RuVLM-Bench: Русскоязычная Vision-Language модель

Проект по обучению и оценке Vision-Language модели (VLM) для русского языка на основе открытых данных от VK. Модель способна обрабатывать изображения и отвечать на вопросы о них на русском языке.


Цель проекта:
Разработка и обучение русскоязычной Vision-Language модели, демонстрирующей работоспособность на бенчмарках GQA-ru и MMBENCH-ru от VK.


Ключевые результаты:
Модель обучена: Vision-Language модель с 649K параметров
Аппаратное ускорение: Обучение на Mac M2 с MPS (Metal Performance Shaders)
Метрики: Достигнута точность 15% на валидационном наборе
Данные: Загружено 800+ примеров из GQA-ru и MMBENCH-ru
Визуализация: Автоматическая генерация графиков обучения


Структура проекта

ruvlm-bench/
├── data/                    # Датасеты (GQA-ru, MMBENCH-ru)
├── src/                     # Исходный код
│   ├── models/             # Архитектуры моделей
│   ├── utils/              # Вспомогательные функции
│   └── configs/            # Конфигурации
├── scripts/                 # Исполняемые скрипты
│   ├── download_fixed.py   # Загрузка данных
│   ├── train_final.py      # Обучение модели
│   ├── evaluate_real.py    # Оценка модели
│   └── check_data_structure.py # Проверка данных
├── notebooks/              # Jupyter ноутбуки для анализа
├── results/                # Результаты экспериментов
│   └── final/              # Финальные результаты
│       ├── best_model.pt   # Лучшая модель
│       ├── final_model.pt  # Финальная модель
│       ├── checkpoints/    # Чекпоинты обучения
│       └── training_history.png # Графики обучения
├── tests/                  # Тесты
├── docs/                   # Документация
├── requirements.txt        # Зависимости Python
└── README.md              # Этот файл


Быстрый старт

1. Установка зависимостей
# Клонирование репозитория
git clone <repository-url>
cd ruvlm-bench

# Создание виртуального окружения
python -m venv .venv
source .venv/bin/activate  # На Mac/Linux
# или .venv\Scripts\activate  # На Windows

# Установка зависимостей
pip install -r requirements.txt

2. Загрузка данных
# Загрузка датасетов GQA-ru и MMBENCH-ru
python scripts/download_fixed.py

3. Обучение модели
# Обучение VLM модели
python scripts/train_final.py

4. Оценка результатов
# Оценка обученной модели
python scripts/evaluate_real.py


Используемые датасеты

Датасет	Примеров	Описание
GQA-ru	500	Вопросы по изображениям на русском языке
MMBENCH-ru	300	Множественный выбор по изображениям
Источник данных: VK Vision-Language Modeling Collection



Результаты обучения

Модель 1.0 (финальная)

Архитектура: CNN + LSTM
Параметры: 649,610
Batch size: 4
Learning rate: 0.001
Эпохи: 5
Train loss: 1.44 (начальный: 2.20)
Val accuracy: 15.0%
Время обучения: ~5 минут 


Пример работы модели

Вход:
  Изображение: человек в рубашке
  Вопрос: "Кто в рубашке?"

Обработка:
  1. CNN извлекает визуальные признаки
  2. LSTM обрабатывает текст вопроса
  3. Объединение мультимодальных признаков
  4. Классификация на 10 классов

Выход:
  Предсказанный класс: 5 (уверенность: 93%)
Настройка для разных платформ


Метрики оценки:
Текущие результаты:
GQA-ru accuracy: 15.0% (валидация)
MMBENCH-ru accuracy: 0.0% (требует адаптации для множественного выбора)
Loss reduction: 34.5% (2.20 → 1.44)
